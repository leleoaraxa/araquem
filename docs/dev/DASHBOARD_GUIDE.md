# ğŸ“Š Manual Operacional â€” Dashboards de Observabilidade Araquem (v2.1.1)

**Projeto:** Plataforma de InteligÃªncia ImobiliÃ¡ria SIRIOS â€” *Araquem*
**VersÃ£o:** M7.6 (ConsolidaÃ§Ã£o Grafana)
**Autor:** Sirius (AI Observability Framework)
**Data:** *(auto-gerado na atualizaÃ§Ã£o do painel)*

---

## ğŸ¯ 1. Objetivo Geral

Os dashboards do Araquem foram redesenhados para oferecer **poucos painÃ©is**, porÃ©m **completos e acionÃ¡veis** â€” eliminando redundÃ¢ncias e maximizando o valor visual da telemetria.

Cada dashboard responde a uma **pergunta fundamental** do sistema:

| Dashboard                       | Pergunta-chave                                                               |
| ------------------------------- | ---------------------------------------------------------------------------- |
| **00_SIRIOS_OVERVIEW**          | O sistema estÃ¡ saudÃ¡vel e entregando resultados dentro dos SLOs?             |
| **10_API_SLO_PIPELINE**         | Onde o tempo Ã© gasto no pipeline `/ask` e quais gargalos impactam o SLO?     |
| **20_PLANNER_RAG_INTELLIGENCE** | O Planner e o RAG estÃ£o inteligentes, coerentes e atualizados?               |
| **30_OPS_RELIABILITY**          | A infraestrutura e os processos automÃ¡ticos estÃ£o consistentes e confiÃ¡veis? |

Esses quatro painÃ©is cobrem todo o ciclo de inteligÃªncia do Araquem: **do input da pergunta atÃ© a qualidade da resposta**.

---

## ğŸ§­ 2. Estrutura e NavegaÃ§Ã£o

Os dashboards sÃ£o provisionados automaticamente (via `grafana/provisioning/`) e agrupados na pasta **â€œSirios Dashboardsâ€** do Grafana.

### VariÃ¡veis globais

Todos compartilham variÃ¡veis (no topo da tela):

* `job` â€” normalmente `araquem-api`
* `entity` â€” domÃ­nio em anÃ¡lise (`fiis_cadastro`, `fiis_precos`, etc.)
* `intent` â€” intenÃ§Ã£o do usuÃ¡rio (`cadastro`, `preÃ§os`, `dividendos`, etc.)
* `store` â€” Ã­ndice RAG (`embeddings.jsonl`)
* `interval` â€” janela temporal (ex.: `1h`, `6h`, `24h`, `7d`)

### Cores e convenÃ§Ãµes

* **Verde:** dentro do SLO.
* **Amarelo:** em tendÃªncia de risco (80â€“95% do limite).
* **Vermelho:** fora do limite (â‰¥ limiar YAML).
* **Cinza:** mÃ©trica nÃ£o disponÃ­vel.

---

## ğŸ§© 3. Dashboard 00 â€” SIRIOS_OVERVIEW

**FunÃ§Ã£o:** visÃ£o executiva â€” saÃºde global do sistema.

### O que observar

* **KPIs de topo** (linha de cards):

  * **Throughput:** perguntas/minuto (proxy de uso).
  * **Erro (%):** relaÃ§Ã£o entre erros e requisiÃ§Ãµes.
  * **LatÃªncia p95:** tempo mÃ¡ximo aceitÃ¡vel (SLO: â‰¤ 1500 ms).
  * **Cache Hit Ratio:** eficiÃªncia de cache (> 60% ideal).
  * **RAG Density:** documentos por MB no Ã­ndice (indicador de qualidade de embeddings).
  * **Ãšltimo Refresh RAG:** tempo desde o Ãºltimo rebuild (ideal â‰¤ 24 h).

* **TendÃªncias:**

  * TrÃ¡fego por status HTTP â†’ estabilidade e padrÃ£o de uso.
  * LatÃªncia p50/p95/p99 â†’ detectar variaÃ§Ã£o diurna.

* **Alertas embutidos:**

  * LatÃªncia > 1500 ms â†’ pipeline sobrecarregado.
  * Erros > 1% â†’ possÃ­vel falha lÃ³gica ou infra.
  * RAG sem refresh > 24 h â†’ risco de respostas desatualizadas.
  * Cache hit < 60% â†’ possÃ­vel invalidaÃ§Ã£o ou carga fria.

### Como ler

* **Verde constante** â†’ operaÃ§Ã£o saudÃ¡vel.
* **Amarelo frequente** â†’ planejar re-otimizaÃ§Ã£o.
* **Vermelho persistente** â†’ abrir incidente observabilidade nÃ­vel 1.

### Acompanhamento

* Checar diariamente durante o horÃ¡rio de pico (â‰ˆ 10hâ€“15h).
* Registrar variaÃ§Ãµes > 20% no canal â€œ#sirios-opsâ€.

---

## âš™ï¸ 4. Dashboard 10 â€” API_SLO_PIPELINE

**FunÃ§Ã£o:** engenharia â€” entender o desempenho interno do pipeline `/ask`.

### SeÃ§Ãµes principais

1. **SLO de LatÃªncia**

   * DistribuiÃ§Ã£o p50/p95/p99 (histogram_quantile).
   * Comparar perÃ­odos de carga vs perÃ­odos ociosos.
2. **Taxa de Erros**

   * Por status ou cÃ³digo especÃ­fico.
3. **Pipeline Stages**

   * DivisÃµes lÃ³gicas: *Planner â†’ SQL â†’ Formatter â†’ Responder*.
   * Quando hÃ¡ tracing ativo, clicar em â€œTempo Traceâ€ â†’ redireciona ao Tempo com o span `/ask`.
4. **Heatmap Entidade Ã— Intent**

   * Mostra variaÃ§Ã£o de latÃªncia por domÃ­nio.
5. **Tabela de Resultados**

   * MÃ©dia de `rows_total` (retornos por query).

### O que olhar

* p95 > 1500 ms â†’ gargalo.
* Erros concentrados em uma entidade â†’ provÃ¡vel SQL ou cache.
* Gap grande p50â†’p95 â†’ inconsistÃªncia de cache.

### FrequÃªncia recomendada

* Durante deploys ou apÃ³s novos intents/entidades.
* Mensalmente, para comparar tendÃªncia histÃ³rica.

---

## ğŸ§  5. Dashboard 20 â€” PLANNER_RAG_INTELLIGENCE

**FunÃ§Ã£o:** inteligÃªncia semÃ¢ntica e qualidade do Ã­ndice de conhecimento.

### Planner

* **Top intents** por volume â†’ identificar concentraÃ§Ã£o de uso.
* **Planner score mÃ©dio** â†’ avaliar confianÃ§a das classificaÃ§Ãµes.
* **Unroutables / Misses** â†’ devem ser < 1 %.

### RAG Index

* **Docs & Size:** verifica crescimento do JSONL.
* **Density Score:** docs / MB â€” alvo > 10 docs/MB.
* **Last Refresh:** tempo desde Ãºltimo rebuild â€” ideal < 24 h.
* **CorrelaÃ§Ã£o p95 Ã— Density:** densidades baixas costumam aumentar latÃªncia.

### Crons

* **rag-refresh-cron:** frequÃªncia e sucesso das execuÃ§Ãµes.
* Ãšltimo log > 24 h â†’ alerta preventivo.

### Leitura estratÃ©gica

* Queda de density â†’ indice â€œrarefeitoâ€ (embeddings velhos).
* Crescimento muito rÃ¡pido â†’ duplicaÃ§Ã£o de chunks.
* Misses planner â†‘ â†’ ajustar ontologia/tokens.

---

## ğŸ§° 6. Dashboard 30 â€” OPS_RELIABILITY

**FunÃ§Ã£o:** confiabilidade operacional e processos automatizados.

### SeÃ§Ãµes

1. **Cache**

   * Hits Ã— Misses (por entidade).
   * Hit ratio global (ideal â‰¥ 60 %).
   * Picos de miss â†’ reindexaÃ§Ãµes ou flushes.
2. **Quality Gate**

   * MÃ©tricas `quality_top1_accuracy` e `quality_routed_rate`.
   * Valores de referÃªncia: 95% / 90%.
3. **Infraestrutura**

   * Job `araquem-api` â†’ `up == 1`.
   * Redis / DB â†’ latÃªncia e conexÃµes (se expostas).
4. **Crons**

   * `quality-cron` e `rag-refresh-cron` â†’ Ãºltima execuÃ§Ã£o OK.
   * Erros ou falhas â†’ logs de `docker logs`.

### O que olhar

* Queda repentina no hit ratio ou routed rate â†’ sintomas de drift.
* Qualquer cron > 24 h sem execuÃ§Ã£o â†’ agir.

---

## ğŸ” 7. Como acompanhar na rotina

| FrequÃªncia              | AÃ§Ã£o                                                         |
| ----------------------- | ------------------------------------------------------------ |
| **Diariamente (manhÃ£)** | Verificar *Overview*: latÃªncia, erros, refresh RAG.          |
| **ApÃ³s deploy**         | Revisar *API_SLO_PIPELINE* e *OPS_RELIABILITY*.              |
| **Semanalmente**        | Analisar *Planner_RAG_INTELLIGENCE* para drift semÃ¢ntico.    |
| **Mensalmente**         | Exportar mÃ©tricas agregadas p/ relatÃ³rios de confiabilidade. |

---

## ğŸ§® 8. Alertas e thresholds

Os limites sÃ£o definidos em `data/ops/observability.yaml`.
Grafana usa esses valores diretamente â€” **sem hardcode**.

| MÃ©trica                            | Limiar    | AÃ§Ã£o                      |
| ---------------------------------- | --------- | ------------------------- |
| `api_latency_p95`                  | > 1500 ms | revisar SQL e cache       |
| `api_error_rate`                   | > 1%      | inspecionar logs `/ask`   |
| `cache_hit_ratio`                  | < 60%     | invalidar cache e aquecer |
| `rag_index_last_refresh_timestamp` | > 24 h    | forÃ§ar rebuild            |
| `rag_index_density_score`          | < 10      | reindexar embeddings      |
| `quality_top1_accuracy`            | < 95%     | revisar testes de QA      |
| `quality_routed_rate`              | < 90%     | revisar ontologia         |

---

## ğŸ”’ 9. GovernanÃ§a dos Dashboards

* Todos os dashboards sÃ£o **gerados automaticamente** via `scripts/observability/gen_dashboards.py`.
* O versionamento Ã© controlado em `grafana/dashboards/_README.md` e no Git.
* AlteraÃ§Ãµes manuais **nÃ£o devem ser feitas diretamente** no JSON.
* A atualizaÃ§Ã£o segue o ciclo:

  1. Editar `data/ops/observability.yaml`
  2. Rodar `python scripts/observability/gen_dashboards.py`
  3. Revisar no Grafana
  4. Commitar a nova versÃ£o (`feat(obs): regenerate dashboards`)

---

## ğŸ§  10. Filosofia de Observabilidade SIRIOS

> **â€œMedir Ã© a forma de aprender.â€**

O Araquem nÃ£o mede para vigiar, mede para **melhorar com consciÃªncia**.
Cada mÃ©trica exposta e cada dashboard tÃªm um propÃ³sito claro:

* **Executivo:** medir entrega e estabilidade.
* **Engenharia:** medir gargalos e causas.
* **IA/Ontologia:** medir coerÃªncia e aprendizado.
* **OperaÃ§Ãµes:** medir confiabilidade e rotina.

A junÃ§Ã£o desses quatro nÃ­veis forma o ciclo contÃ­nuo de melhoria que sustenta a IA SIRIOS.

---

### ğŸ“˜ Dica final

No canto superior direito de cada dashboard hÃ¡ um **Ã­cone de â€œ?â€** com o link para este documento (`docs/dev/DASHBOARD_GUIDE.md`).
Manteremos ambos versionados juntos: sempre que o dashboard mudar, o guia tambÃ©m muda.

---
