# üìò RAG Index Store ‚Äî EmbeddingStore (Araquem M12)

**M√≥dulo:** `app/rag/index_reader.py`
**Classe principal:** `EmbeddingStore`
**Papel:** Ler o √≠ndice de embeddings (`embeddings.jsonl`) em disco e expor buscas por similaridade (vetor ou texto), de forma **determin√≠stica**, **cacheada** e independente de LLM.

---

## 1. Vis√£o Geral

O **Index Store** √© a camada respons√°vel por:

1. Ler o arquivo de embeddings em formato **JSONL** (um JSON por linha).
2. Manter um cache em mem√≥ria respeitando:

   * caminho f√≠sico do arquivo,
   * hash do manifest,
   * `mtime` do arquivo (modifica√ß√£o em disco).
3. Expor duas opera√ß√µes principais:

   * `search_by_vector(qvec, k, min_score)`
   * `search_by_text(text, embedder, k)`
4. Calcular similaridade via **cosseno** entre o vetor da pergunta e o vetor do chunk.

Ele √© consumido diretamente pelo `Context Builder` (`app/rag/context_builder.py`), que monta o contexto final enviado para o Narrator.

---

## 2. Formato do √≠ndice de embeddings (`embeddings.jsonl`)

Cada linha do arquivo `embeddings.jsonl` √© um JSON com, no m√≠nimo:

* `embedding`: lista de n√∫meros (`List[float]`) representando o vetor do chunk.

Campos t√≠picos usados em outras camadas:

* `text` / `content` / `body` / `snippet`: conte√∫do textual do chunk.
* `collection`: cole√ß√£o √† qual o chunk pertence (ex.: `fiis_noticias`).
* `id`, `doc_id`, `chunk_id`, `entity`, `tags`, etc.: metadados adicionais.

Exemplo ilustrativo de uma linha:

```json
{
  "id": "row-1",
  "embedding": [0.12, -0.03, 0.44, ...],
  "text": "Not√≠cia relevante sobre HGLG11...",
  "collection": "fiis_noticias",
  "entity": "fiis_noticias",
  "doc_id": "doc-123",
  "chunk_id": "chunk-001"
}
```

> **Importante:**
>
> * O `EmbeddingStore` exige apenas que `embedding` exista e seja um vetor v√°lido.
> * A normaliza√ß√£o de texto e metadados √© feita pelo `Context Builder` via `_normalize_chunk`.

---

## 3. Cache e Manifest

A classe usa um cache global `_EMB_CACHE`:

```python
_EMB_CACHE = {"key": None, "rows": None, "mtime": None}
```

Na inicializa√ß√£o:

1. Resolve o caminho absoluto para `embeddings.jsonl`.

2. L√™ o `manifest.json` no mesmo diret√≥rio e calcula um **hash** via:

   ```python
   manifest_hash = get_manifest_hash(str(manifest_path))
   ```

3. Monta uma chave de cache:

   ```python
   cache_key = (resolved_path, manifest_hash)
   ```

4. L√™ `mtime` do arquivo (`stat().st_mtime`).

Se:

* o cache j√° tem linhas (`rows`),
* o `cache_key` atual √© igual ao do cache,
* e o `mtime` n√£o mudou (ou √© compat√≠vel via `math.isclose`),

ent√£o o `EmbeddingStore` **reusa** as linhas j√° carregadas em mem√≥ria.

Caso contr√°rio:

* reabre o arquivo,
* l√™ todas as linhas,
* faz `json.loads(line)` uma a uma,
* atualiza `_EMB_CACHE`.

> Resultado:
>
> * altera√ß√µes em `embeddings.jsonl` ou `manifest.json` invalidam o cache,
> * opera√ß√µes subsequentes reutilizam o conte√∫do em mem√≥ria, evitando rereads custosos.

---

## 4. Filtros b√°sicos: `rows_with_vectors()`

M√©todo:

```python
def rows_with_vectors(self) -> List[Dict[str, Any]]:
    """Retorna somente linhas com vetor n√£o-vazio (sanity)."""
    return [r for r in self._rows if _has_vec(r)]
```

* `_has_vec(row)` verifica:

  * `embedding` √© uma lista,
  * comprimento > 0,
  * todos os elementos s√£o `int` ou `float`.

Esse m√©todo √© usado internamente pela busca.
Linhas sem vetor v√°lido **nunca** entram no ranking.

---

## 5. Similaridade: `_cos(a, b)`

A similaridade √© calculada pelo **cosseno** entre dois vetores:

```python
dot = sum(x * y for x, y in zip(a, b))
na = sqrt(sum(x * x for x in a))
nb = sqrt(sum(x * x for x in b))
score = (dot / (na * nb)) if (na > 0 and nb > 0) else 0.0
```

Propriedades:

* vetores paralelos ‚Üí score ‚âà 1.0
* vetores ortogonais ‚Üí score ‚âà 0.0
* vetores opostos ‚Üí score ‚âà -1.0 (na pr√°tica, valores negativos podem ser filtrados via `min_score`).

---

## 6. Busca por vetor: `search_by_vector`

Assinatura:

```python
def search_by_vector(
    self,
    qvec: List[float],
    k: int = 5,
    min_score: float | None = None,
) -> List[Dict[str, Any]]:
```

Passos:

1. Obt√©m apenas linhas v√°lidas:

   ```python
   rows = self.rows_with_vectors()
   ```

2. Calcula `(score, row)` para cada linha:

   ```python
   scored = [(_cos(qvec, r["embedding"]), r) for r in rows]
   ```

3. Ordena por `score` decrescente:

   ```python
   scored.sort(key=lambda t: t[0], reverse=True)
   ```

4. Constr√≥i uma lista de dicts:

   ```python
   ranked = [dict(score=s, **r) for s, r in scored]
   ```

5. Se `min_score` foi definido, filtra:

   ```python
   if min_score is not None:
       ranked = [r for r in ranked if float(r.get("score", 0.0)) >= min_score]
   ```

6. Retorna apenas os `k` primeiros:

   ```python
   return ranked[:k]
   ```

> O `score` √© sempre inclu√≠do no resultado (campo num√©rico).
> Esse campo √© aproveitado pelo `Context Builder` para filtrar e pelo Narrator/Explain para transpar√™ncia.

---

## 7. Busca por texto: `search_by_text`

Assinatura:

```python
def search_by_text(self, text: str, embedder, k: int = 5) -> List[Dict[str, Any]]:
    """
    Usa um cliente de embeddings compat√≠vel (ex.: OllamaClient)
    que exp√µe .embed([text]) -> [[float]].
    """
```

Passos:

1. Chama o cliente de embeddings:

   ```python
   vecs = embedder.embed([text]) or []
   qvec = vecs[0] if vecs and isinstance(vecs[0], list) else []
   ```

2. Em caso de exce√ß√£o ou vetor vazio ‚Üí retorna `[]`.

3. Caso contr√°rio, delega para `search_by_vector(qvec, k=k)`.

> **Importante:**
>
> * Essa fun√ß√£o n√£o sabe nada sobre intents/entities.
> * Ela apenas converte texto em vetor e delega a busca vetorial.

---

## 8. Integra√ß√£o com Context Builder

O `Context Builder` usa o `EmbeddingStore` assim:

```python
from app.rag.index_reader import EmbeddingStore
from app.utils.filecache import cached_embedding_store

store: EmbeddingStore = cached_embedding_store(_RAG_INDEX_PATH)
embedder = OllamaClient()
vectors = embedder.embed([question])
qvec = vectors[0] ...
results = store.search_by_vector(qvec, k=max_chunks_val, min_score=min_score_val) or []
```

E depois normaliza os resultados via `_normalize_chunk`, montando o contexto final.

O campo `collection` de cada linha √© utilizado como metadado (`used_collections` e `policy.collections`), e √© configurado indiretamente via:

* `data/policies/rag.yaml` ‚Üí `entities.fiis_noticias.collections = ["fiis_noticias"]`
* pipeline de indexa√ß√£o ‚Üí coloca `collection="fiis_noticias"` em cada chunk de not√≠cias.

---

## 9. Garantias de Testes (M12)

Os testes em `tests/rag/test_index_reader.py` exercitam:

1. **Inicializa√ß√£o:**

   * arquivo inexistente ‚Üí `FileNotFoundError`.
2. **Filtragem:**

   * `rows_with_vectors()` descarta linhas com embedding vazio.
3. **Ranking:**

   * `search_by_vector()` ordena corretamente por similaridade.
   * `min_score` filtra resultados abaixo do threshold.
4. **Integra√ß√£o com embedder:**

   * `search_by_text()`:

     * usa `embedder.embed([text])`,
     * delega para `search_by_vector()`,
     * em caso de erro ou vetor vazio ‚Üí retorna `[]`.

Esses testes garantem que o `EmbeddingStore` √©:

* determin√≠stico,
* seguro contra dados ruins,
* isolado de detalhes de LLM (o embedder √© s√≥ uma depend√™ncia expl√≠cita).

---

## 10. Evolu√ß√µes Futuras (M12+)

Poss√≠veis incrementos, sem quebrar o contrato atual:

1. **Filtro por `collection` diretamente na busca**, usando informa√ß√µes da policy (`rag.entities.*.collections`).
2. Exposi√ß√£o de m√©tricas internas (ex.: contagem de rows, distribui√ß√£o de scores) para a camada de observabilidade.
3. Sanitiza√ß√£o adicional de embeddings (ex.: norma zero, normaliza√ß√£o expl√≠cita).

Qualquer evolu√ß√£o deve manter:

* o formato do `embeddings.jsonl` compat√≠vel,
* a API p√∫blica de `EmbeddingStore` (`rows_with_vectors`, `search_by_vector`, `search_by_text`),
* o acoplamento m√≠nimo com o restante do RAG (Context Builder continua sendo o orquestrador de intents/entities).

---
