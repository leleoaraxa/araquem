version: 2
datasource: prometheus
datasource_uid: grafana

bindings:
  api_requests_total: "api_requests_total"
  api_latency_bucket: "api_latency_ms_bucket"
  api_latency_sum: "api_latency_ms_sum"
  api_latency_count: "api_latency_ms_count"
  api_errors_total: "api_errors_total"
  cache_hits_total: "cache_hits_total"
  cache_misses_total: "cache_misses_total"
  rag_index_size_total: "rag_index_size_total"
  rag_index_docs_total: "rag_index_docs_total"
  rag_index_last_refresh_timestamp: "rag_index_last_refresh_timestamp"
  rag_index_density_score: "rag_index_density_score"
  rag_eval_recall_at_5: "rag_eval_recall_at_5"
  rag_eval_recall_at_10: "rag_eval_recall_at_10"
  rag_eval_mrr: "rag_eval_mrr"
  rag_eval_ndcg_at_10: "rag_eval_ndcg_at_10"
  rag_eval_last_run_timestamp: "rag_eval_last_run_timestamp"
  quality_top1_accuracy: "quality_top1_accuracy"
  quality_routed_rate: "quality_routed_rate"
  cron_last_run_timestamp: "cron_last_run_timestamp"
  cron_last_status: "cron_last_status"

labels:
  job: "job"
  instance: "instance"
  entity: "entity"
  intent: "intent"
  route: "route"
  result_key: "result_key"
  status: "status"
  private: "private"
  store: "store"
  cron: "cron"

thresholds:
  api:
    slo_ms_p95: 1500
    error_rate_pct: 1.0
  rag:
    max_refresh_age_hours: 24
    min_density_docs_per_mb: 10
  cache:
    min_hit_ratio_pct: 60
  quality:
    min_top1_accuracy_pct: 95
    min_routed_rate_pct: 90
  narrator:
    # SLO de referência para o Narrator (quando habilitado)
    slo_ms_p95: 2500
  rag_eval:
    min_recall_at_5_pct: 60
    min_recall_at_10_pct: 70
    min_mrr: 0.50
    min_ndcg_at_10: 0.60

alerts:
  windows:
    short: 5m
    long: 15m
  receivers:
    slack_webhook_url: ""
    email: ""

variables:
  default_job: "araquem-api"
  default_entity: "fiis_registrations"
  default_intent: "cadastro"
  default_store: "embeddings.jsonl"

services:
  gateway:
    metrics:
      http_requests_total: { enabled: true }
      http_request_duration_seconds:
        enabled: true
        buckets: [0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1, 2, 5]
      ws_messages_total:
        enabled: true
    tracing:
      enabled: true
      sampling:
        root_ratio: 0.2
        slow_threshold_ms: 300
      pii:
        drop_attributes: ["nickname", "question_raw"]
        allow_attributes: ["request_id", "client_id", "user_kind", "route", "method"]
  orchestrator:
    metrics:
      planner_route_decisions_total: { enabled: true }
      planner_duration_seconds:
        enabled: true
        buckets: [0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25]
      planner_explain_enabled_total: { enabled: true }
      planner_explain_latency_seconds:
        enabled: true
        buckets: [0.01, 0.05, 0.1, 0.25, 0.5, 1, 2]
      planner_explain_nodes_total: { enabled: true }
      planner_explain_weight_sum_total: { enabled: true }
      planner_intent_score:
        enabled: true
        buckets: [0, 1, 2, 3, 5, 8, 13, 21]
      planner_entity_score:
        enabled: true
        buckets: [0, 1, 2, 3, 5, 8, 13, 21]
      planner_explain_decision_depth: { enabled: true }
      planner_routed_total: { enabled: true }
      planner_top1_match_total: { enabled: true }
      planner_confusion_total: { enabled: true }
      planner_top2_gap_histogram:
        enabled: true
        buckets: [0.0, 0.5, 1, 2, 3, 5]
      planner_quality_last_gap: { enabled: true }
      planner_blocked_by_threshold_total: { enabled: true }
    tracing:
      enabled: true
      attributes_allow: ["intent","entity","confidence","ontology_version","tokens_matched"]
  executor:
    metrics:
      sql_query_duration_seconds:
        enabled: true
        buckets: [0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1, 2]
      sql_rows_returned_total: { enabled: true }
      sql_errors_total: { enabled: true }
    tracing:
      enabled: true
      statement:
        sanitize: true
        max_len: 512
  cache:
    metrics:
      cache_ops_total: { enabled: true }
      cache_latency_seconds:
        enabled: true
        buckets: [0.0005,0.001,0.005,0.01,0.025,0.05,0.1]
      cache_key_ttl_seconds:
        enabled: true
        buckets: [10, 30, 60, 300, 600, 3600]
    tracing:
      enabled: true
      key_handling: hash_sha256
  narrator:
    metrics:
      sirios_narrator_render_total:
        enabled: true
        # outcome: ok | error
        labels: [outcome]
      sirios_narrator_shadow_total:
        enabled: true
        # outcome: ok | error
        labels: [outcome]
      sirios_narrator_latency_ms:
        enabled: true
        # buckets em milissegundos
        # inclui cauda longa para capturar casos de 10s–50s (antes ficava "cego" acima de 5s)
        buckets: [50, 100, 200, 300, 500, 750, 1000, 1500, 2000, 5000, 10000, 20000, 30000, 45000, 60000]

      sirios_narrator_tokens_in_total:
        enabled: true
        labels: [entity, strategy]
      sirios_narrator_tokens_out_total:
        enabled: true
        labels: [entity, strategy]
      sirios_narrator_prompt_chars_total:
        enabled: true
        labels: [entity, strategy]
      sirios_narrator_prompt_rows_total:
        enabled: true
        labels: [entity, strategy]
      services_narrator_llm_requests_total:
        enabled: true
        labels: [bucket, entity, outcome]
      services_narrator_llm_latency_seconds:
        enabled: true
        labels: [bucket, entity]
global:
  grafana:
    dashboards:
      enable_tempo_links: true
  exporters:
    otlp_endpoint: "http://otel-collector:4317"
    prometheus_scrape_path: "/metrics"
